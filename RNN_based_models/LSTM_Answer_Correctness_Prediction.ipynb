{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_Answer_Correctness_Prediction.ipynb","provenance":[{"file_id":"1VnKaROL4rSBgW8xitMAo0ELgF_p4ETdG","timestamp":1616829293614},{"file_id":"1GVJP4XAbDUkqfUxTYrpkXS_Jrsl0MeBw","timestamp":1616015844607}],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1PhthoR3JNvBRx2j95tf3shurbLboSaIz","authorship_tag":"ABX9TyOkAG02/1iw8Vy3uE8Yeb1o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"farifxiKU1aB"},"source":["import numpy as np\n","import pandas as pd\n","import warnings\n","import gc\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import random\n","from random import choice\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential \n","from tensorflow.keras.layers import Dense, LSTM, Concatenate, Embedding, Flatten, Activation, Dropout\n","from sklearn.model_selection import KFold\n","from tensorflow.python.client import device_lib\n","warnings.filterwarnings('ignore')\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOson70GPOXb"},"source":["import gc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BQsVybBH3VPw"},"source":["## Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"rwtTusGxrmAE","colab":{"base_uri":"https://localhost:8080/","height":345},"executionInfo":{"status":"ok","timestamp":1616834779997,"user_tz":240,"elapsed":56000,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"b4331346-dc38-4ed5-9ef2-5961d1e96a99"},"source":["# load the data\n","import pandas as pd\n","dataframe = pd.read_csv(\"/content/drive/MyDrive/dlresearch/Practice_Log_Demographics.csv\") \n","dataframe.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>term</th>\n","      <th>Final_Exam</th>\n","      <th>Final_Exam_Std</th>\n","      <th>Final_Exam_Percent</th>\n","      <th>Final_Exam_0_1</th>\n","      <th>Final_Exam_log_trans</th>\n","      <th>Dropped</th>\n","      <th>SNPSHT_RPT_DT</th>\n","      <th>STDNT_SEX_CD</th>\n","      <th>gender</th>\n","      <th>birthYear</th>\n","      <th>birthMonth</th>\n","      <th>STDNT_ASIAN_IND</th>\n","      <th>STDNT_BLACK_IND</th>\n","      <th>STDNT_HWIAN_IND</th>\n","      <th>STDNT_HSPNC_IND</th>\n","      <th>STDNT_NTV_AMRCN_IND</th>\n","      <th>STDNT_WHITE_IND</th>\n","      <th>STDNT_ETHNC_GRP_CD</th>\n","      <th>ethnicity</th>\n","      <th>STDNT_MULTI_ETHNC_IND</th>\n","      <th>STDNT_HSPNC_LATINO_IND</th>\n","      <th>nativeEnglish</th>\n","      <th>FIRST_US_PRMNNT_RES_PSTL_CD</th>\n","      <th>FIRST_US_PRMNNT_RES_PSTL_5_CD</th>\n","      <th>FRST_FRGN_PRMNNT_RES_CNTRY_CD</th>\n","      <th>permanentCountry</th>\n","      <th>STDNT_CTZN_STAT_CD</th>\n","      <th>USCitizenship</th>\n","      <th>STDNT_CTZN_CNTRY_1_CD</th>\n","      <th>citizenship</th>\n","      <th>STDNT_CTZN_CNTRY_2_CD</th>\n","      <th>STDNT_CTZN_CNTRY_2_DES</th>\n","      <th>international</th>\n","      <th>FIRST_TERM_ATTND_CD</th>\n","      <th>firstTerm</th>\n","      <th>FIRST_TERM_ATTND_BEGIN_YR_MO</th>\n","      <th>FIRST_TERM_ATTND_END_YR_MO</th>\n","      <th>LAST_TERM_ATTND_CD</th>\n","      <th>...</th>\n","      <th>Freshman</th>\n","      <th>Junior</th>\n","      <th>Sophomore</th>\n","      <th>Senior</th>\n","      <th>Minors_1</th>\n","      <th>Minors_2OrMore</th>\n","      <th>athlete_1</th>\n","      <th>honorsPro_1</th>\n","      <th>program_Cat</th>\n","      <th>LSA</th>\n","      <th>programBusiness</th>\n","      <th>programEngineering</th>\n","      <th>programInformation</th>\n","      <th>programOther</th>\n","      <th>interaction_count</th>\n","      <th>activeCode_count</th>\n","      <th>codelens_count</th>\n","      <th>mChoice_count</th>\n","      <th>pageVideoViews_count</th>\n","      <th>parsons_count</th>\n","      <th>interaction_days</th>\n","      <th>spacing</th>\n","      <th>user_id.x</th>\n","      <th>practice_count</th>\n","      <th>practice_days</th>\n","      <th>user_id.y</th>\n","      <th>course_name.y</th>\n","      <th>chapter_label</th>\n","      <th>sub_chapter_label</th>\n","      <th>question_name</th>\n","      <th>i_interval</th>\n","      <th>e_factor</th>\n","      <th>q</th>\n","      <th>trials_num</th>\n","      <th>day's_available_flashcards</th>\n","      <th>start_practice</th>\n","      <th>end_practice</th>\n","      <th>timezoneoffset</th>\n","      <th>next_eligible_date</th>\n","      <th>days_offset</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>WN 2018</td>\n","      <td>0.892</td>\n","      <td>1.199159</td>\n","      <td>89.2</td>\n","      <td>0.883168</td>\n","      <td>2.4681</td>\n","      <td>0</td>\n","      <td>09-FEB-21</td>\n","      <td>1</td>\n","      <td>Female</td>\n","      <td>1998</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>White</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Native</td>\n","      <td>02052-3110</td>\n","      <td>2052.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>U.S. Citzn</td>\n","      <td>USA</td>\n","      <td>United States</td>\n","      <td></td>\n","      <td></td>\n","      <td>0</td>\n","      <td>2110</td>\n","      <td>FA 2016</td>\n","      <td>2016/09</td>\n","      <td>2016/12</td>\n","      <td>2270</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>LS&amp;A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5913.0</td>\n","      <td>2965.0</td>\n","      <td>556.0</td>\n","      <td>636.0</td>\n","      <td>1342.0</td>\n","      <td>60.0</td>\n","      <td>68.0</td>\n","      <td>23.016143</td>\n","      <td>148</td>\n","      <td>493</td>\n","      <td>44</td>\n","      <td>148</td>\n","      <td>UMSI106</td>\n","      <td>Functions</td>\n","      <td>DecodingaFunction</td>\n","      <td>test_questionfunctions_3_3</td>\n","      <td>1</td>\n","      <td>1.96</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>14</td>\n","      <td>2018-02-10 12:03:08</td>\n","      <td>2018-02-10 12:04:01</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>WN 2018</td>\n","      <td>0.892</td>\n","      <td>1.199159</td>\n","      <td>89.2</td>\n","      <td>0.883168</td>\n","      <td>2.4681</td>\n","      <td>0</td>\n","      <td>09-FEB-21</td>\n","      <td>1</td>\n","      <td>Female</td>\n","      <td>1998</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>White</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Native</td>\n","      <td>02052-3110</td>\n","      <td>2052.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>U.S. Citzn</td>\n","      <td>USA</td>\n","      <td>United States</td>\n","      <td></td>\n","      <td></td>\n","      <td>0</td>\n","      <td>2110</td>\n","      <td>FA 2016</td>\n","      <td>2016/09</td>\n","      <td>2016/12</td>\n","      <td>2270</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>LS&amp;A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5913.0</td>\n","      <td>2965.0</td>\n","      <td>556.0</td>\n","      <td>636.0</td>\n","      <td>1342.0</td>\n","      <td>60.0</td>\n","      <td>68.0</td>\n","      <td>23.016143</td>\n","      <td>148</td>\n","      <td>493</td>\n","      <td>44</td>\n","      <td>148</td>\n","      <td>UMSI106</td>\n","      <td>Tuples</td>\n","      <td>UnpackingDictionaryItems</td>\n","      <td>ee_ch09_05</td>\n","      <td>1</td>\n","      <td>1.40</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2018-02-20 13:31:37</td>\n","      <td>2018-02-20 13:31:41</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>WN 2018</td>\n","      <td>0.892</td>\n","      <td>1.199159</td>\n","      <td>89.2</td>\n","      <td>0.883168</td>\n","      <td>2.4681</td>\n","      <td>0</td>\n","      <td>09-FEB-21</td>\n","      <td>1</td>\n","      <td>Female</td>\n","      <td>1998</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>White</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Native</td>\n","      <td>02052-3110</td>\n","      <td>2052.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>U.S. Citzn</td>\n","      <td>USA</td>\n","      <td>United States</td>\n","      <td></td>\n","      <td></td>\n","      <td>0</td>\n","      <td>2110</td>\n","      <td>FA 2016</td>\n","      <td>2016/09</td>\n","      <td>2016/12</td>\n","      <td>2270</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>LS&amp;A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5913.0</td>\n","      <td>2965.0</td>\n","      <td>556.0</td>\n","      <td>636.0</td>\n","      <td>1342.0</td>\n","      <td>60.0</td>\n","      <td>68.0</td>\n","      <td>23.016143</td>\n","      <td>148</td>\n","      <td>493</td>\n","      <td>44</td>\n","      <td>148</td>\n","      <td>UMSI106</td>\n","      <td>NestedData</td>\n","      <td>DebuggingNestedData</td>\n","      <td>ee_nested_data_011</td>\n","      <td>15</td>\n","      <td>2.50</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>2018-03-16 14:09:57</td>\n","      <td>2018-03-16 14:10:33</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>WN 2018</td>\n","      <td>0.892</td>\n","      <td>1.199159</td>\n","      <td>89.2</td>\n","      <td>0.883168</td>\n","      <td>2.4681</td>\n","      <td>0</td>\n","      <td>09-FEB-21</td>\n","      <td>1</td>\n","      <td>Female</td>\n","      <td>1998</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>White</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Native</td>\n","      <td>02052-3110</td>\n","      <td>2052.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>U.S. Citzn</td>\n","      <td>USA</td>\n","      <td>United States</td>\n","      <td></td>\n","      <td></td>\n","      <td>0</td>\n","      <td>2110</td>\n","      <td>FA 2016</td>\n","      <td>2016/09</td>\n","      <td>2016/12</td>\n","      <td>2270</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>LS&amp;A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5913.0</td>\n","      <td>2965.0</td>\n","      <td>556.0</td>\n","      <td>636.0</td>\n","      <td>1342.0</td>\n","      <td>60.0</td>\n","      <td>68.0</td>\n","      <td>23.016143</td>\n","      <td>148</td>\n","      <td>493</td>\n","      <td>44</td>\n","      <td>148</td>\n","      <td>UMSI106</td>\n","      <td>SimplePythonData</td>\n","      <td>FunctionCalls</td>\n","      <td>exercise_functionCalls_1</td>\n","      <td>16</td>\n","      <td>2.60</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>2018-01-30 14:15:49</td>\n","      <td>2018-01-30 14:15:58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>WN 2018</td>\n","      <td>0.892</td>\n","      <td>1.199159</td>\n","      <td>89.2</td>\n","      <td>0.883168</td>\n","      <td>2.4681</td>\n","      <td>0</td>\n","      <td>09-FEB-21</td>\n","      <td>1</td>\n","      <td>Female</td>\n","      <td>1998</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>White</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Native</td>\n","      <td>02052-3110</td>\n","      <td>2052.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>U.S. Citzn</td>\n","      <td>USA</td>\n","      <td>United States</td>\n","      <td></td>\n","      <td></td>\n","      <td>0</td>\n","      <td>2110</td>\n","      <td>FA 2016</td>\n","      <td>2016/09</td>\n","      <td>2016/12</td>\n","      <td>2270</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>LS&amp;A</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5913.0</td>\n","      <td>2965.0</td>\n","      <td>556.0</td>\n","      <td>636.0</td>\n","      <td>1342.0</td>\n","      <td>60.0</td>\n","      <td>68.0</td>\n","      <td>23.016143</td>\n","      <td>148</td>\n","      <td>493</td>\n","      <td>44</td>\n","      <td>148</td>\n","      <td>UMSI106</td>\n","      <td>SimplePythonData</td>\n","      <td>DataTypes</td>\n","      <td>test_question2_1_2</td>\n","      <td>59</td>\n","      <td>2.10</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>12</td>\n","      <td>2018-03-13 14:22:54</td>\n","      <td>2018-03-13 14:23:16</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>54</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 760 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0     term  ...  next_eligible_date  days_offset\n","0           1  WN 2018  ...                   0           23\n","1           2  WN 2018  ...                   0           33\n","2           3  WN 2018  ...                   0           57\n","3           4  WN 2018  ...                   0           12\n","4           5  WN 2018  ...                   0           54\n","\n","[5 rows x 760 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"OCbHnEp_Vir0"},"source":["#sort data based on timestamp\n","dataframe = dataframe.sort_values(by=['start_practice'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0RvF7BvEr98o"},"source":["FEATURES = ['Repeated', 'chapter_label', 'sub_chapter_label','question_name','user_id','term',\n","            'STDNT_SEX_CD', \n","            'NonNativeEnglish',\n","            'White',\n","            'Asian',\n","            'WhiteOrAsian',\n","            'Hispanic',\n","            'AfricanAmerican',\n","            'OtherEthnicities',\n","            'NonWhiteOrAsian',\n","            'STDNT_CTZN_STAT_CD', 'international', \n","            'gradingType',\n","            'birthYear',\n","            'exclClassCumGPA',\n","            'Freshman',\n","            'Junior',\n","            'Sophomore',\n","            'Senior',\n","            'termCreditsGPA',\n","            'termCreditsNoGPA',\n","            'athlete_1',\n","            'honorsPro',\n","            'LSA', 'programBusiness', 'programEngineering', \n","            'programInformation', 'programOther',\n","            'HSCalculusTaken', \n","            'highSchoolGPA', \n","            'majorsCount', 'minorsCount',\n","            'PREV_TERM_CUM_GPA',\n","            'classGraded', 'classHonors', \n","            'Pass_Fail', \n","            'parentsGraduateEdu',  'minorityGroup', \n","            'q',\n","            'available_flashcards', \n","            'start_practice', \n","            'end_practice',\n","            'days_offset']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mn341X7lSztl"},"source":["dataframe['available_flashcards'] = dataframe[\"day's_available_flashcards\"][:]\n","dataframe = dataframe.drop([\"day's_available_flashcards\"], axis=1)\n","dataframe['user_id'] = dataframe[\"user_id.y\"][:]\n","dataframe = dataframe.drop([\"user_id.y\"], axis=1)\n","dataframe = dataframe.drop([\"user_id.x\"], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_BRggOjbBjN","executionInfo":{"status":"ok","timestamp":1616834804493,"user_tz":240,"elapsed":80466,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"c96bdc02-6edc-4c4a-f6ea-e6cbda17d070"},"source":["gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["61"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXM7MlonVeRL","executionInfo":{"status":"ok","timestamp":1616834805656,"user_tz":240,"elapsed":81619,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"9ec2fedb-56c8-4551-fe93-20ca0df5b467"},"source":["dataframe = dataframe[FEATURES]\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["52"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"2WAFv5z3A6fK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616834806377,"user_tz":240,"elapsed":82330,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"93120df5-cb31-4dce-fc51-97b4fcebfd1b"},"source":["dataframe = dataframe.fillna(0)\n","#transform q value so that if it is >= 4 it would be\n","#considered as 1 (correct) and if <4 0(incorrect)\n","dataframe['answer_correct'] = np.where(dataframe['q']>=4, 1, 0)\n","dataframe['answer_correct'].mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5326395552433993"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"qRKqF_0IXZgj"},"source":["#label encode term, chapter_label, question_name, sub_chapter_label columns\n","dataframe['term'] = dataframe['term'].astype('category')\n","dataframe['user_id'] = dataframe['user_id'].astype(int)\n","dataframe['user_id'] = dataframe['user_id'].astype(str)\n","dataframe['user_id'] = dataframe['term'].str.cat(dataframe['user_id'], sep=':')\n","dataframe['user_id'] = dataframe['user_id'].astype('category')\n","dataframe['chapter_label'] = dataframe['chapter_label'].astype('category')\n","dataframe['sub_chapter_label'] = dataframe['sub_chapter_label'].astype('category')\n","dataframe['question_name'] = dataframe['question_name'].astype('category')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eVl_067GWkDe"},"source":["#calculate time_lag and prev_time_elapsed\n","dataframe['prev_time_elapsed'] = None\n","dataframe['time_lag'] = None\n","dataframe['time_lag'] = dataframe['time_lag'].astype(np.float)\n","dataframe['prev_time_elapsed'] = dataframe['prev_time_elapsed'].astype(np.float)\n","dataframe.start_practice = pd.to_datetime(dataframe.start_practice, format='%Y-%m-%d %H:%M:%S')\n","dataframe.end_practice = pd.to_datetime(dataframe.end_practice, format='%Y-%m-%d %H:%M:%S')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xrkcn9VhWETm","executionInfo":{"status":"ok","timestamp":1616834818453,"user_tz":240,"elapsed":94377,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"98d5eb8f-c4f0-4cd6-94d1-eb9e28d93030"},"source":["from tqdm import tqdm\n","for user in tqdm(dataframe['user_id'].unique()):\n","    tmp_user = dataframe[dataframe['user_id']==user]\n","    tmp_time_elapsed = tmp_user.end_practice.apply(lambda a: a.timestamp()) - tmp_user.start_practice.apply(lambda a: a.timestamp())\n","    #shifting time elapsed by one\n","    #so that time_elapsed row for each question\n","    #would refer to the time that user took to answer\n","    #previous question\n","    tmp_time_elapsed = np.insert(np.array(tmp_time_elapsed[:-1]), 0, -1., axis=0)\n","    indices = tmp_user.index\n","    start_row = indices[0]\n","    dataframe['time_lag'].iloc[start_row] = -1\n","    time_substrahend = tmp_user.start_practice.iloc[:-1]\n","    time_substrahend = time_substrahend.apply(lambda a: a.timestamp())\n","    time_substrahend = np.array(time_substrahend)\n","\n","    time_minuend = tmp_user.start_practice.iloc[1:]\n","    time_minuend = time_minuend.apply(lambda a: a.timestamp())\n","    time_minuend = np.array(time_minuend)\n","    \n","    dataframe['prev_time_elapsed'].iloc[indices] = tmp_time_elapsed\n","    dataframe['time_lag'].iloc[indices[1:]] = time_minuend - time_substrahend"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 887/887 [00:11<00:00, 79.54it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S96YQhUGZ-Au","executionInfo":{"status":"ok","timestamp":1616834818745,"user_tz":240,"elapsed":94665,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"dfaffb54-3695-428f-feca-e108f0388562"},"source":["# remove students who are taking the course for a second time\n","dataframe  = dataframe[dataframe['Repeated'] == ' ']\n","gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"8t8yZ0XvWwzz"},"source":["#drop column end_practice\n","dataframe.drop(columns=['end_practice'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E42raRIrYYXz"},"source":["# calculate the age feature\n","dataframe['term_value'] = [int(ele[3:]) for ele in dataframe['term']]\n","dataframe['age'] = dataframe['term_value'] - dataframe['birthYear']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pcMVQXueYnMh"},"source":["# drop term_value and birthYear column\n","dataframe.drop(columns=['term_value', 'birthYear'], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hjRF5szkcQE0"},"source":["# convert minors_count to int value\n","new_minors_count = []\n","for i in dataframe['minorsCount']:\n","  if i == 0 or i == '0':\n","    new_minors_count.append(0)\n","  elif i == '1 Minor':\n","    new_minors_count.append(1)\n","  else:\n","    new_minors_count.append(2)\n","\n","dataframe['minorsCount'] = new_minors_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VdzvJSw0KUU","executionInfo":{"status":"ok","timestamp":1616834819535,"user_tz":240,"elapsed":95429,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"ae7a59ab-0ad1-47d6-c7bd-ab3610042bc9"},"source":["print(\"we have \", dataframe['user_id'].nunique(),\" users in total.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["we have  881  users in total.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hUaGk9L9g13t"},"source":["for category in ['term','chapter_label', 'sub_chapter_label', 'question_name']:\n","  dataframe[category] =  dataframe[category].cat.codes\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hkyvcYvlhliG"},"source":["NUMERIC_FEATURE =  ['age',\n","            'exclClassCumGPA',\n","            'termCreditsGPA',\n","            'termCreditsNoGPA',\n","            'highSchoolGPA', \n","            'majorsCount', 'minorsCount',\n","            'PREV_TERM_CUM_GPA',\n","            'available_flashcards', \n","            'days_offset', \n","            'prev_time_elapsed',\n","             'time_lag']\n","# z-score normalize the numerical features\n","for f in NUMERIC_FEATURE:\n","  m = dataframe[f].mean()\n","  std = dataframe[f].std()\n","  dataframe[f] = (dataframe[f] - m)/std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wo2OH-d5kWp1"},"source":["FEATURE_TRANS =  ['answer_correct', 'chapter_label', 'sub_chapter_label','question_name','user_id','term',\n","                  'STDNT_SEX_CD', \n","                    'White','Asian','NonWhiteOrAsian',\n","            'STDNT_CTZN_STAT_CD', 'international', \n","            'age',\n","            'exclClassCumGPA',\n","           'Freshman',\n","            'Junior',\n","            'Sophomore',\n","            'Senior',\n","            'termCreditsGPA',\n","            'termCreditsNoGPA',\n","            'athlete_1',\n","            'honorsPro',\n","            'LSA', 'programBusiness', 'programEngineering', \n","            'programInformation', 'programOther',\n","            'HSCalculusTaken', \n","            'highSchoolGPA', \n","\n","            'majorsCount', 'minorsCount',\n","\n","            'PREV_TERM_CUM_GPA',\n","            'classGraded', 'classHonors', \n","            'Pass_Fail', \n","            'parentsGraduateEdu',  'minorityGroup', \n","            'available_flashcards', \n","            'days_offset', 'prev_time_elapsed',\n","             'time_lag']\n","grouped_data = dataframe[FEATURE_TRANS].groupby(['user_id']).apply(lambda r: (\n","                r['answer_correct'],\n","                r['term'],\n","                r['chapter_label'],\n","                r['sub_chapter_label'],\n","                r['question_name'],\n","                np.array([r['STDNT_SEX_CD'],r['STDNT_CTZN_STAT_CD'], r['international'], \n","                  r['White'],r['Asian'],r['NonWhiteOrAsian'],\n","                 r['age'],r['exclClassCumGPA'],\n","                r['Freshman'], r['Junior'], r['Sophomore'], r['Senior'],\n","                r['termCreditsGPA'], r['termCreditsNoGPA'],\n","                r['athlete_1'], r['honorsPro'],\n","                r['LSA'], r['programBusiness'], r['programEngineering'], \n","                r['programInformation'], r['programOther'],\n","                r['HSCalculusTaken'],  r['highSchoolGPA'], \n","                r['majorsCount'], r['minorsCount'],\n","                r['PREV_TERM_CUM_GPA'], \n","                r['parentsGraduateEdu'], r['minorityGroup'],\n","                r['available_flashcards'],\n","                r['days_offset'],\n","                r['prev_time_elapsed'],\n","                r['time_lag']\n","              ]).transpose()\n","                ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XXLqQnjrlp_4","executionInfo":{"status":"ok","timestamp":1616834822259,"user_tz":240,"elapsed":98129,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"d5c03682-ae78-4ee6-c1e5-9685a11c4625"},"source":["gc.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"QYGQasdTrmP0"},"source":["# remove students who don't have make any interactions with the tool\n","toRemove = []\n","for index in grouped_data.index:\n","  if len(grouped_data[index][0]) <= 10:\n","    toRemove.append(index)\n","grouped_data = grouped_data.drop(index=toRemove)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kZqV9siDyNb"},"source":["#SETTINGS -> can be modified at any time\n","MAXLENGTH = 500\n","EMBEDDING_DIM = 128\n","DENSE_NEURON = 16\n","LSTM_NEURON = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MksD1JizpPn"},"source":["FEATURES_SIZE = 38\n","CHAPTER_SIZE = 38\n","SUB_CHAPTER_SIZE = 222\n","QUESTION_SIZE = 1065"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mY3Thp6d0NaT"},"source":["#create dataset class\n","#to prepare it for train, valid, and test sets\n","from torch.utils.data import Dataset, DataLoader\n","class SPACE_DATASET(Dataset):\n","    def __init__(self, data, maxlength = 100):\n","        super(SPACE_DATASET, self).__init__()\n","        self.maxlength = maxlength\n","        self.data = data\n","        self.users = list()\n","        for user in data.index:\n","            self.users.append(user)\n","\n","    def __len__(self):\n","        return len(self.users)\n","    \n","    def __getitem__(self, ix):\n","        user = self.users[ix]\n","        user = user\n","        target, term, ch_label, sub_ch_label, ques_name, features = self.data[user]\n","        \n","        #0s should be used as padding values\n","        ori_target = target.values \n","        term = term.values\n","        ch_label = ch_label.values + 1\n","        sub_ch_label = sub_ch_label.values +1\n","        ques_name = ques_name.values + 1\n","        \n","        n = len(ch_label)\n","\n","        # one hot for term\n","        term_encode = [0]*6\n","        term_encode[term[0]] = 1\n","        shifted_target= []\n","\n","        \n","        # get  user interaction informations in the previous MAXLEN interactions\n","        if n > self.maxlength:\n","          ch_label = ch_label[-self.maxlength:]\n","          sub_ch_label = sub_ch_label[-self.maxlength:]\n","          ques_name = ques_name[-self.maxlength:]\n","          features = features[-self.maxlength:]\n","          target = ori_target[-self.maxlength:]\n","          shifted_target = ori_target[ (-self.maxlength - 1) :-1]\n","        else:\n","          ch_label = [0]*(self.maxlength - n)+list(ch_label[:])\n","          sub_ch_label = [0]*(self.maxlength - n)+list(sub_ch_label[:])\n","          ques_name = [0]*(self.maxlength - n)+list(ques_name[:])\n","          features = [[0]*len(features[0])]*(self.maxlength  - n)+list(features[:])\n","          target = [-1]*(self.maxlength - n) + list(ori_target[:])\n","          shifted_target = [-1]*(self.maxlength + 1 - n) + list(ori_target[:-1])\n","\n","        new_features = []\n","        count = 0\n","        for f in features:\n","          temp = list(f)\n","          temp.extend(term_encode)\n","          # temp.append(shifted_target[count]) #uncomment this line for include previous response feature\n","          new_features.append(temp)\n","          \n","          count += 1\n","        \n","        features = new_features\n","        \n","        return ch_label,sub_ch_label,ques_name,features,target"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4xc90-aLzxat"},"source":["## KFOLD - LSTM\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzJrljnjzypP","executionInfo":{"status":"ok","timestamp":1616835108319,"user_tz":240,"elapsed":384148,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"0f4874d7-9353-4d89-c417-9936181cc667"},"source":["# 5 fold cross validation with GRU-based model\n","import torch\n","X = np.array(grouped_data.keys())\n","kfold = KFold(n_splits=5, shuffle=True)\n","train_losses = list()\n","train_aucs = list()\n","val_losses = list()\n","val_aucs = list()\n","train_eval= list()\n","test_eval = list()\n","for train, test in kfold.split(X):\n","    users_train, users_test =  X[train], X[test]\n","    n = len(users_test)//2\n","    users_test, users_val = users_test[:n], users_test[n: ]\n","    train_data_space = SPACE_DATASET(grouped_data[users_train], MAXLENGTH)\n","    val_data_space = SPACE_DATASET(grouped_data[users_val], MAXLENGTH)\n","    test_data_space = SPACE_DATASET(grouped_data[users_test], MAXLENGTH)\n","    #construct training input\n","    train_chapter=[]\n","    train_sub_chapter=[]\n","    train_question = []\n","    train_features=[]\n","    train_labels=[]\n","    for i in range(len(users_train)):\n","        user = train_data_space.__getitem__(i)\n","        train_chapter.append(user[0])\n","        train_sub_chapter.append(user[1]) \n","        train_question.append(user[2])\n","        train_features.append(user[3])\n","        train_labels.append(user[4])\n","    train_chapter = np.array(train_chapter)\n","    train_sub_chapter = np.array(train_sub_chapter)\n","    train_question = np.array(train_question)\n","    train_features = np.array(train_features)\n","    train_labels= np.array(train_labels)[..., np.newaxis]\n","\n","    #construct validation input\n","    val_chapter=[]\n","    val_sub_chapter=[]\n","    val_question = []\n","    val_features=[]\n","    val_labels=[]\n","    for i in range(len(users_val)):\n","        user = val_data_space.__getitem__(i)\n","        val_chapter.append(user[0])\n","        val_sub_chapter.append(user[1]) \n","        val_question.append(user[2])\n","        val_features.append(user[3])\n","        val_labels.append(user[4])\n","    val_chapter = np.array(val_chapter)\n","    val_sub_chapter = np.array(val_sub_chapter)\n","    val_features = np.array(val_features)\n","    val_question = np.array(val_question)\n","    val_labels= np.array(val_labels)[..., np.newaxis]\n","\n","    # construct test input\n","    test_chapter=[]\n","    test_sub_chapter=[]\n","    test_features=[]\n","    test_question=[]\n","    test_labels=[]\n","    for i in range(len(users_test)):\n","        user = test_data_space.__getitem__(i)\n","        test_chapter.append(user[0])\n","        test_sub_chapter.append(user[1]) \n","        test_question.append(user[2])\n","        test_features.append(user[3])\n","        test_labels.append(user[4])\n","    test_chapter = np.array(test_chapter)\n","    test_sub_chapter = np.array(test_sub_chapter)\n","    test_features = np.array(test_features)\n","    test_question = np.array(test_question)\n","    test_labels= np.array(test_labels)[..., np.newaxis]\n","\n","    # define loss function and evaluation metrics\n","    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","    acc = tf.keras.metrics.Accuracy()\n","    auc = tf.keras.metrics.AUC()\n","\n","    def masked_bce(y_true, y_pred):\n","      flat_pred = y_pred\n","      flat_ground_truth = y_true\n","      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n","      return bce(flat_ground_truth, flat_pred, sample_weight=label_mask)\n","\n","    def masked_acc(y_true, y_pred):\n","      flat_pred = y_pred\n","      flat_ground_truth = y_true\n","      flat_pred = (flat_pred >= 0.5)\n","      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n","      return acc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n","\n","    def masked_auc(y_true, y_pred):\n","      flat_pred = y_pred\n","      flat_ground_truth = y_true\n","      label_mask = tf.math.not_equal(flat_ground_truth, -1)\n","      return auc(flat_ground_truth, flat_pred, sample_weight=label_mask)\n","\n","    # input layer\n","    input_chap = tf.keras.Input(shape=(MAXLENGTH))\n","    input_sub_chap = tf.keras.Input(shape=(MAXLENGTH))\n","    input_ques =  tf.keras.Input(shape=(MAXLENGTH))\n","    input_features = tf.keras.Input(shape=(MAXLENGTH, FEATURES_SIZE))\n","\n","    # embedding layer for categorical features\n","    embedding_chap = Embedding(input_dim = CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_chap)\n","    embedding_sub_chap = Embedding(input_dim = SUB_CHAPTER_SIZE, output_dim = EMBEDDING_DIM)(input_sub_chap) \n","    embedding_ques = Embedding(input_dim = QUESTION_SIZE, output_dim = EMBEDDING_DIM)(input_ques)       \n","\n","    # dense layer for numeric features\n","    dense_features = Dense(EMBEDDING_DIM,input_shape = (None, MAXLENGTH))(input_features)\n","\n","\n","\n","    # lstm layers\n","    lstm_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_chap)\n","    lstm_sub_chap = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_sub_chap)\n","    lstm_ques = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(embedding_ques)\n","    lstm_features = LSTM(LSTM_NEURON, input_shape = (None, EMBEDDING_DIM),return_sequences = True)(dense_features)\n","\n","    lstm_output = tf.concat([lstm_chap, lstm_sub_chap, lstm_ques,lstm_features], axis = 2)\n","\n","    dense1 = Dense(256, input_shape = (None, 4*EMBEDDING_DIM), activation='relu')(lstm_output)\n","    dropout1 = Dropout(0.1)(dense1)\n","    dense2 = Dense(64, input_shape = (None, 256), activation='relu')(dropout1)\n","    dropout2 = Dropout(0.1)(dense2)\n","    pred = Dense(1, input_shape = (None, 64), activation='sigmoid')(dropout2)\n","\n","    model = tf.keras.Model(\n","        inputs=[input_chap, input_sub_chap,input_ques, input_features],\n","        outputs=pred,\n","        name='lstm_model'\n","    )\n","\n","    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","    opt_adam = Adam(learning_rate = 0.005)\n","    model.compile(\n","        optimizer=opt_adam,\n","        loss= masked_bce,\n","        metrics = [masked_acc, masked_auc]\n","    )\n","\n","    history = model.fit(\n","      [train_chapter, train_sub_chapter, train_question, train_features],\n","      train_labels,\n","      batch_size = 64,\n","      epochs = 100,\n","      validation_data=([val_chapter, val_sub_chapter, val_question, val_features], val_labels),\n","      callbacks=[callback]\n","    )\n","    val_losses.append(list(history.history['val_loss']))\n","    train_losses.append(list(history.history['loss']))\n","    val_aucs.append(list(history.history['val_masked_auc']))\n","    train_aucs.append(list(history.history['masked_auc']))\n","    train_score = model.evaluate([train_chapter, train_sub_chapter, train_question, train_features], train_labels)\n","    train_eval.append(train_score)\n","    test_score = model.evaluate([test_chapter, test_sub_chapter, test_question, test_features], test_labels)\n","    test_eval.append(test_score)\n","    print(\"Test: \", test_score)\n","    def reset_weights(model):\n","      for layer in model.layers: \n","        if isinstance(layer, tf.keras.Model):\n","          reset_weights(layer)\n","          continue\n","        for k, initializer in layer.__dict__.items():\n","          if \"initializer\" not in k:\n","            continue\n","          # find the corresponding variable\n","          var = getattr(layer, k.replace(\"_initializer\", \"\"))\n","          var.assign(initializer(var.shape, var.dtype))\n","    reset_weights(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","11/11 [==============================] - 40s 363ms/step - loss: 0.6194 - masked_acc: 0.5216 - masked_auc: 0.5270 - val_loss: 0.5419 - val_masked_acc: 0.6136 - val_masked_auc: 0.6551\n","Epoch 2/100\n","11/11 [==============================] - 1s 114ms/step - loss: 0.5430 - masked_acc: 0.6313 - masked_auc: 0.6790 - val_loss: 0.4907 - val_masked_acc: 0.6609 - val_masked_auc: 0.7197\n","Epoch 3/100\n","11/11 [==============================] - 1s 109ms/step - loss: 0.4921 - masked_acc: 0.6705 - masked_auc: 0.7320 - val_loss: 0.4761 - val_masked_acc: 0.6863 - val_masked_auc: 0.7520\n","Epoch 4/100\n","11/11 [==============================] - 1s 103ms/step - loss: 0.4774 - masked_acc: 0.6916 - masked_auc: 0.7586 - val_loss: 0.4674 - val_masked_acc: 0.7013 - val_masked_auc: 0.7699\n","Epoch 5/100\n","11/11 [==============================] - 1s 108ms/step - loss: 0.4689 - masked_acc: 0.7047 - masked_auc: 0.7738 - val_loss: 0.4671 - val_masked_acc: 0.7112 - val_masked_auc: 0.7813\n","Epoch 6/100\n","11/11 [==============================] - 1s 106ms/step - loss: 0.4570 - masked_acc: 0.7139 - masked_auc: 0.7844 - val_loss: 0.4609 - val_masked_acc: 0.7187 - val_masked_auc: 0.7898\n","Epoch 7/100\n","11/11 [==============================] - 1s 106ms/step - loss: 0.4590 - masked_acc: 0.7207 - masked_auc: 0.7920 - val_loss: 0.4668 - val_masked_acc: 0.7242 - val_masked_auc: 0.7958\n","Epoch 8/100\n","11/11 [==============================] - 1s 107ms/step - loss: 0.4528 - masked_acc: 0.7259 - masked_auc: 0.7976 - val_loss: 0.4551 - val_masked_acc: 0.7289 - val_masked_auc: 0.8009\n","Epoch 9/100\n","11/11 [==============================] - 1s 103ms/step - loss: 0.4524 - masked_acc: 0.7302 - masked_auc: 0.8023 - val_loss: 0.4623 - val_masked_acc: 0.7330 - val_masked_auc: 0.8053\n","Epoch 10/100\n","11/11 [==============================] - 1s 108ms/step - loss: 0.4412 - masked_acc: 0.7341 - masked_auc: 0.8066 - val_loss: 0.4569 - val_masked_acc: 0.7364 - val_masked_auc: 0.8091\n","Epoch 11/100\n","11/11 [==============================] - 1s 107ms/step - loss: 0.4441 - masked_acc: 0.7374 - masked_auc: 0.8101 - val_loss: 0.4607 - val_masked_acc: 0.7394 - val_masked_auc: 0.8123\n","Epoch 12/100\n","11/11 [==============================] - 1s 108ms/step - loss: 0.4369 - masked_acc: 0.7403 - masked_auc: 0.8133 - val_loss: 0.4617 - val_masked_acc: 0.7419 - val_masked_auc: 0.8151\n","Epoch 13/100\n","11/11 [==============================] - 1s 104ms/step - loss: 0.4364 - masked_acc: 0.7427 - masked_auc: 0.8160 - val_loss: 0.4663 - val_masked_acc: 0.7442 - val_masked_auc: 0.8175\n","Epoch 14/100\n","11/11 [==============================] - 1s 103ms/step - loss: 0.4344 - masked_acc: 0.7450 - masked_auc: 0.8184 - val_loss: 0.4581 - val_masked_acc: 0.7464 - val_masked_auc: 0.8199\n","Epoch 15/100\n","11/11 [==============================] - 1s 102ms/step - loss: 0.4290 - masked_acc: 0.7471 - masked_auc: 0.8207 - val_loss: 0.4591 - val_masked_acc: 0.7484 - val_masked_auc: 0.8221\n","Epoch 16/100\n","11/11 [==============================] - 1s 106ms/step - loss: 0.4292 - masked_acc: 0.7491 - masked_auc: 0.8228 - val_loss: 0.4660 - val_masked_acc: 0.7502 - val_masked_auc: 0.8241\n","Epoch 17/100\n","11/11 [==============================] - 1s 104ms/step - loss: 0.4234 - masked_acc: 0.7508 - masked_auc: 0.8247 - val_loss: 0.4605 - val_masked_acc: 0.7519 - val_masked_auc: 0.8259\n","Epoch 18/100\n","11/11 [==============================] - 1s 105ms/step - loss: 0.4200 - masked_acc: 0.7525 - masked_auc: 0.8266 - val_loss: 0.4669 - val_masked_acc: 0.7535 - val_masked_auc: 0.8277\n","22/22 [==============================] - 2s 38ms/step - loss: 0.4150 - masked_acc: 0.7542 - masked_auc: 0.8286\n","3/3 [==============================] - 0s 38ms/step - loss: 0.4855 - masked_acc: 0.7550 - masked_auc: 0.8295\n","Test:  [0.4854532480239868, 0.7549843788146973, 0.8294782638549805]\n","Epoch 1/100\n","12/12 [==============================] - 9s 283ms/step - loss: 0.6264 - masked_acc: 0.5687 - masked_auc: 0.5441 - val_loss: 0.5708 - val_masked_acc: 0.6063 - val_masked_auc: 0.6365\n","Epoch 2/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.5507 - masked_acc: 0.6247 - masked_auc: 0.6633 - val_loss: 0.5244 - val_masked_acc: 0.6519 - val_masked_auc: 0.7034\n","Epoch 3/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4985 - masked_acc: 0.6625 - masked_auc: 0.7176 - val_loss: 0.5055 - val_masked_acc: 0.6788 - val_masked_auc: 0.7397\n","Epoch 4/100\n","12/12 [==============================] - 1s 101ms/step - loss: 0.4847 - masked_acc: 0.6846 - masked_auc: 0.7471 - val_loss: 0.4954 - val_masked_acc: 0.6937 - val_masked_auc: 0.7590\n","Epoch 5/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4796 - masked_acc: 0.6974 - masked_auc: 0.7637 - val_loss: 0.4856 - val_masked_acc: 0.7040 - val_masked_auc: 0.7717\n","Epoch 6/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4785 - masked_acc: 0.7067 - masked_auc: 0.7748 - val_loss: 0.4917 - val_masked_acc: 0.7112 - val_masked_auc: 0.7800\n","Epoch 7/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4720 - masked_acc: 0.7131 - masked_auc: 0.7821 - val_loss: 0.4860 - val_masked_acc: 0.7163 - val_masked_auc: 0.7858\n","Epoch 8/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4706 - masked_acc: 0.7177 - masked_auc: 0.7876 - val_loss: 0.4891 - val_masked_acc: 0.7203 - val_masked_auc: 0.7905\n","Epoch 9/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4662 - masked_acc: 0.7215 - masked_auc: 0.7918 - val_loss: 0.4877 - val_masked_acc: 0.7236 - val_masked_auc: 0.7943\n","Epoch 10/100\n","12/12 [==============================] - 1s 101ms/step - loss: 0.4675 - masked_acc: 0.7247 - masked_auc: 0.7954 - val_loss: 0.5028 - val_masked_acc: 0.7267 - val_masked_auc: 0.7977\n","Epoch 11/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4613 - masked_acc: 0.7277 - masked_auc: 0.7987 - val_loss: 0.4866 - val_masked_acc: 0.7294 - val_masked_auc: 0.8005\n","Epoch 12/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4561 - masked_acc: 0.7303 - masked_auc: 0.8015 - val_loss: 0.5049 - val_masked_acc: 0.7318 - val_masked_auc: 0.8032\n","Epoch 13/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4578 - masked_acc: 0.7325 - masked_auc: 0.8039 - val_loss: 0.4794 - val_masked_acc: 0.7338 - val_masked_auc: 0.8054\n","Epoch 14/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4538 - masked_acc: 0.7345 - masked_auc: 0.8062 - val_loss: 0.4982 - val_masked_acc: 0.7356 - val_masked_auc: 0.8074\n","Epoch 15/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4527 - masked_acc: 0.7361 - masked_auc: 0.8080 - val_loss: 0.4854 - val_masked_acc: 0.7372 - val_masked_auc: 0.8092\n","Epoch 16/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4528 - masked_acc: 0.7377 - masked_auc: 0.8097 - val_loss: 0.4819 - val_masked_acc: 0.7386 - val_masked_auc: 0.8108\n","Epoch 17/100\n","12/12 [==============================] - 1s 101ms/step - loss: 0.4489 - masked_acc: 0.7391 - masked_auc: 0.8114 - val_loss: 0.4911 - val_masked_acc: 0.7401 - val_masked_auc: 0.8125\n","Epoch 18/100\n","12/12 [==============================] - 1s 100ms/step - loss: 0.4608 - masked_acc: 0.7404 - masked_auc: 0.8128 - val_loss: 0.4826 - val_masked_acc: 0.7409 - val_masked_auc: 0.8134\n","Epoch 19/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4541 - masked_acc: 0.7413 - masked_auc: 0.8138 - val_loss: 0.4974 - val_masked_acc: 0.7419 - val_masked_auc: 0.8145\n","Epoch 20/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4590 - masked_acc: 0.7423 - masked_auc: 0.8149 - val_loss: 0.4844 - val_masked_acc: 0.7428 - val_masked_auc: 0.8155\n","Epoch 21/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4516 - masked_acc: 0.7432 - masked_auc: 0.8159 - val_loss: 0.4821 - val_masked_acc: 0.7437 - val_masked_auc: 0.8165\n","Epoch 22/100\n","12/12 [==============================] - 1s 100ms/step - loss: 0.4491 - masked_acc: 0.7441 - masked_auc: 0.8168 - val_loss: 0.4800 - val_masked_acc: 0.7445 - val_masked_auc: 0.8174\n","Epoch 23/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4547 - masked_acc: 0.7449 - masked_auc: 0.8177 - val_loss: 0.4799 - val_masked_acc: 0.7454 - val_masked_auc: 0.8183\n","23/23 [==============================] - 1s 41ms/step - loss: 0.4451 - masked_acc: 0.7458 - masked_auc: 0.8187\n","3/3 [==============================] - 0s 39ms/step - loss: 0.4905 - masked_acc: 0.7463 - masked_auc: 0.8192\n","Test:  [0.49047985672950745, 0.7463119029998779, 0.819211483001709]\n","Epoch 1/100\n","12/12 [==============================] - 9s 249ms/step - loss: 0.6148 - masked_acc: 0.5784 - masked_auc: 0.5598 - val_loss: 0.5522 - val_masked_acc: 0.6226 - val_masked_auc: 0.6601\n","Epoch 2/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.5457 - masked_acc: 0.6382 - masked_auc: 0.6829 - val_loss: 0.4993 - val_masked_acc: 0.6626 - val_masked_auc: 0.7178\n","Epoch 3/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.5002 - masked_acc: 0.6715 - masked_auc: 0.7296 - val_loss: 0.4831 - val_masked_acc: 0.6857 - val_masked_auc: 0.7484\n","Epoch 4/100\n","12/12 [==============================] - 1s 99ms/step - loss: 0.4837 - masked_acc: 0.6912 - masked_auc: 0.7554 - val_loss: 0.4702 - val_masked_acc: 0.6998 - val_masked_auc: 0.7662\n","Epoch 5/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4776 - masked_acc: 0.7034 - masked_auc: 0.7705 - val_loss: 0.4718 - val_masked_acc: 0.7093 - val_masked_auc: 0.7776\n","Epoch 6/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4766 - masked_acc: 0.7116 - masked_auc: 0.7801 - val_loss: 0.4718 - val_masked_acc: 0.7153 - val_masked_auc: 0.7846\n","Epoch 7/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4699 - masked_acc: 0.7172 - masked_auc: 0.7867 - val_loss: 0.5030 - val_masked_acc: 0.7203 - val_masked_auc: 0.7901\n","Epoch 8/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4741 - masked_acc: 0.7217 - masked_auc: 0.7918 - val_loss: 0.4668 - val_masked_acc: 0.7240 - val_masked_auc: 0.7943\n","Epoch 9/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4693 - masked_acc: 0.7252 - masked_auc: 0.7957 - val_loss: 0.4644 - val_masked_acc: 0.7275 - val_masked_auc: 0.7983\n","Epoch 10/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4637 - masked_acc: 0.7285 - masked_auc: 0.7994 - val_loss: 0.4608 - val_masked_acc: 0.7304 - val_masked_auc: 0.8015\n","Epoch 11/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4592 - masked_acc: 0.7314 - masked_auc: 0.8026 - val_loss: 0.4599 - val_masked_acc: 0.7329 - val_masked_auc: 0.8043\n","Epoch 12/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4575 - masked_acc: 0.7337 - masked_auc: 0.8053 - val_loss: 0.4794 - val_masked_acc: 0.7350 - val_masked_auc: 0.8067\n","Epoch 13/100\n","12/12 [==============================] - 1s 101ms/step - loss: 0.4773 - masked_acc: 0.7353 - masked_auc: 0.8068 - val_loss: 0.4752 - val_masked_acc: 0.7359 - val_masked_auc: 0.8075\n","Epoch 14/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4698 - masked_acc: 0.7363 - masked_auc: 0.8078 - val_loss: 0.4751 - val_masked_acc: 0.7370 - val_masked_auc: 0.8087\n","Epoch 15/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4675 - masked_acc: 0.7374 - masked_auc: 0.8091 - val_loss: 0.4737 - val_masked_acc: 0.7380 - val_masked_auc: 0.8099\n","Epoch 16/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4621 - masked_acc: 0.7384 - masked_auc: 0.8103 - val_loss: 0.4705 - val_masked_acc: 0.7392 - val_masked_auc: 0.8111\n","Epoch 17/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4491 - masked_acc: 0.7396 - masked_auc: 0.8117 - val_loss: 0.4633 - val_masked_acc: 0.7405 - val_masked_auc: 0.8126\n","Epoch 18/100\n","12/12 [==============================] - 1s 101ms/step - loss: 0.4552 - masked_acc: 0.7408 - masked_auc: 0.8130 - val_loss: 0.4763 - val_masked_acc: 0.7414 - val_masked_auc: 0.8137\n","Epoch 19/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4563 - masked_acc: 0.7418 - masked_auc: 0.8140 - val_loss: 0.4712 - val_masked_acc: 0.7424 - val_masked_auc: 0.8146\n","Epoch 20/100\n","12/12 [==============================] - 1s 107ms/step - loss: 0.4718 - masked_acc: 0.7427 - masked_auc: 0.8147 - val_loss: 0.4679 - val_masked_acc: 0.7431 - val_masked_auc: 0.8152\n","Epoch 21/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4547 - masked_acc: 0.7435 - masked_auc: 0.8156 - val_loss: 0.4579 - val_masked_acc: 0.7441 - val_masked_auc: 0.8162\n","Epoch 22/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4454 - masked_acc: 0.7445 - masked_auc: 0.8167 - val_loss: 0.4601 - val_masked_acc: 0.7451 - val_masked_auc: 0.8174\n","Epoch 23/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4433 - masked_acc: 0.7455 - masked_auc: 0.8178 - val_loss: 0.4560 - val_masked_acc: 0.7460 - val_masked_auc: 0.8185\n","Epoch 24/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4510 - masked_acc: 0.7463 - masked_auc: 0.8188 - val_loss: 0.4621 - val_masked_acc: 0.7468 - val_masked_auc: 0.8195\n","Epoch 25/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4387 - masked_acc: 0.7472 - masked_auc: 0.8198 - val_loss: 0.4628 - val_masked_acc: 0.7477 - val_masked_auc: 0.8205\n","Epoch 26/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4369 - masked_acc: 0.7480 - masked_auc: 0.8209 - val_loss: 0.4610 - val_masked_acc: 0.7486 - val_masked_auc: 0.8215\n","Epoch 27/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4377 - masked_acc: 0.7490 - masked_auc: 0.8219 - val_loss: 0.4672 - val_masked_acc: 0.7496 - val_masked_auc: 0.8226\n","Epoch 28/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4379 - masked_acc: 0.7499 - masked_auc: 0.8229 - val_loss: 0.4640 - val_masked_acc: 0.7504 - val_masked_auc: 0.8235\n","Epoch 29/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4314 - masked_acc: 0.7507 - masked_auc: 0.8239 - val_loss: 0.4631 - val_masked_acc: 0.7512 - val_masked_auc: 0.8245\n","Epoch 30/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4306 - masked_acc: 0.7515 - masked_auc: 0.8248 - val_loss: 0.4674 - val_masked_acc: 0.7520 - val_masked_auc: 0.8254\n","Epoch 31/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4344 - masked_acc: 0.7522 - masked_auc: 0.8256 - val_loss: 0.4699 - val_masked_acc: 0.7526 - val_masked_auc: 0.8262\n","Epoch 32/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4327 - masked_acc: 0.7529 - masked_auc: 0.8265 - val_loss: 0.4760 - val_masked_acc: 0.7533 - val_masked_auc: 0.8270\n","Epoch 33/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4255 - masked_acc: 0.7536 - masked_auc: 0.8273 - val_loss: 0.4670 - val_masked_acc: 0.7540 - val_masked_auc: 0.8278\n","23/23 [==============================] - 1s 41ms/step - loss: 0.4214 - masked_acc: 0.7544 - masked_auc: 0.8282\n","3/3 [==============================] - 0s 45ms/step - loss: 0.4960 - masked_acc: 0.7547 - masked_auc: 0.8286\n","Test:  [0.49596136808395386, 0.7547347545623779, 0.82862788438797]\n","Epoch 1/100\n","12/12 [==============================] - 9s 250ms/step - loss: 0.6165 - masked_acc: 0.5617 - masked_auc: 0.5680 - val_loss: 0.5326 - val_masked_acc: 0.6175 - val_masked_auc: 0.6599\n","Epoch 2/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.5349 - masked_acc: 0.6377 - masked_auc: 0.6876 - val_loss: 0.4980 - val_masked_acc: 0.6657 - val_masked_auc: 0.7250\n","Epoch 3/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4984 - masked_acc: 0.6749 - masked_auc: 0.7362 - val_loss: 0.4742 - val_masked_acc: 0.6891 - val_masked_auc: 0.7545\n","Epoch 4/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4845 - masked_acc: 0.6946 - masked_auc: 0.7610 - val_loss: 0.4673 - val_masked_acc: 0.7034 - val_masked_auc: 0.7717\n","Epoch 5/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4741 - masked_acc: 0.7071 - masked_auc: 0.7760 - val_loss: 0.4724 - val_masked_acc: 0.7122 - val_masked_auc: 0.7820\n","Epoch 6/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4744 - masked_acc: 0.7147 - masked_auc: 0.7849 - val_loss: 0.4686 - val_masked_acc: 0.7178 - val_masked_auc: 0.7885\n","Epoch 7/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4759 - masked_acc: 0.7194 - masked_auc: 0.7902 - val_loss: 0.4591 - val_masked_acc: 0.7220 - val_masked_auc: 0.7930\n","Epoch 8/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4673 - masked_acc: 0.7235 - masked_auc: 0.7946 - val_loss: 0.4579 - val_masked_acc: 0.7257 - val_masked_auc: 0.7972\n","Epoch 9/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4636 - masked_acc: 0.7268 - masked_auc: 0.7984 - val_loss: 0.4581 - val_masked_acc: 0.7289 - val_masked_auc: 0.8008\n","Epoch 10/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4577 - masked_acc: 0.7300 - masked_auc: 0.8020 - val_loss: 0.4842 - val_masked_acc: 0.7318 - val_masked_auc: 0.8038\n","Epoch 11/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4648 - masked_acc: 0.7326 - masked_auc: 0.8046 - val_loss: 0.4564 - val_masked_acc: 0.7340 - val_masked_auc: 0.8061\n","Epoch 12/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4620 - masked_acc: 0.7348 - masked_auc: 0.8070 - val_loss: 0.4540 - val_masked_acc: 0.7362 - val_masked_auc: 0.8087\n","Epoch 13/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4565 - masked_acc: 0.7370 - masked_auc: 0.8093 - val_loss: 0.4566 - val_masked_acc: 0.7382 - val_masked_auc: 0.8105\n","Epoch 14/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4567 - masked_acc: 0.7388 - masked_auc: 0.8112 - val_loss: 0.4840 - val_masked_acc: 0.7398 - val_masked_auc: 0.8123\n","Epoch 15/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4689 - masked_acc: 0.7403 - masked_auc: 0.8128 - val_loss: 0.4697 - val_masked_acc: 0.7409 - val_masked_auc: 0.8135\n","Epoch 16/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4577 - masked_acc: 0.7413 - masked_auc: 0.8140 - val_loss: 0.4696 - val_masked_acc: 0.7421 - val_masked_auc: 0.8148\n","Epoch 17/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4657 - masked_acc: 0.7424 - masked_auc: 0.8152 - val_loss: 0.4686 - val_masked_acc: 0.7429 - val_masked_auc: 0.8158\n","Epoch 18/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4581 - masked_acc: 0.7433 - masked_auc: 0.8162 - val_loss: 0.4537 - val_masked_acc: 0.7440 - val_masked_auc: 0.8170\n","Epoch 19/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4490 - masked_acc: 0.7444 - masked_auc: 0.8174 - val_loss: 0.4553 - val_masked_acc: 0.7450 - val_masked_auc: 0.8180\n","Epoch 20/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4473 - masked_acc: 0.7454 - masked_auc: 0.8185 - val_loss: 0.4541 - val_masked_acc: 0.7460 - val_masked_auc: 0.8191\n","Epoch 21/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4436 - masked_acc: 0.7463 - masked_auc: 0.8195 - val_loss: 0.4530 - val_masked_acc: 0.7470 - val_masked_auc: 0.8203\n","Epoch 22/100\n","12/12 [==============================] - 1s 100ms/step - loss: 0.4420 - masked_acc: 0.7473 - masked_auc: 0.8207 - val_loss: 0.4526 - val_masked_acc: 0.7479 - val_masked_auc: 0.8214\n","Epoch 23/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4434 - masked_acc: 0.7482 - masked_auc: 0.8217 - val_loss: 0.4548 - val_masked_acc: 0.7489 - val_masked_auc: 0.8225\n","Epoch 24/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4427 - masked_acc: 0.7491 - masked_auc: 0.8228 - val_loss: 0.4688 - val_masked_acc: 0.7496 - val_masked_auc: 0.8234\n","Epoch 25/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4449 - masked_acc: 0.7499 - masked_auc: 0.8236 - val_loss: 0.4567 - val_masked_acc: 0.7503 - val_masked_auc: 0.8239\n","Epoch 26/100\n","12/12 [==============================] - 1s 102ms/step - loss: 0.4430 - masked_acc: 0.7505 - masked_auc: 0.8242 - val_loss: 0.4629 - val_masked_acc: 0.7509 - val_masked_auc: 0.8246\n","Epoch 27/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4545 - masked_acc: 0.7510 - masked_auc: 0.8248 - val_loss: 0.4575 - val_masked_acc: 0.7514 - val_masked_auc: 0.8252\n","Epoch 28/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4463 - masked_acc: 0.7516 - masked_auc: 0.8255 - val_loss: 0.4562 - val_masked_acc: 0.7520 - val_masked_auc: 0.8259\n","Epoch 29/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4330 - masked_acc: 0.7523 - masked_auc: 0.8263 - val_loss: 0.4466 - val_masked_acc: 0.7527 - val_masked_auc: 0.8267\n","Epoch 30/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4307 - masked_acc: 0.7530 - masked_auc: 0.8270 - val_loss: 0.4467 - val_masked_acc: 0.7534 - val_masked_auc: 0.8275\n","Epoch 31/100\n","12/12 [==============================] - 1s 101ms/step - loss: 0.4333 - masked_acc: 0.7537 - masked_auc: 0.8278 - val_loss: 0.4599 - val_masked_acc: 0.7541 - val_masked_auc: 0.8283\n","Epoch 32/100\n","12/12 [==============================] - 1s 108ms/step - loss: 0.4318 - masked_acc: 0.7543 - masked_auc: 0.8285 - val_loss: 0.4543 - val_masked_acc: 0.7547 - val_masked_auc: 0.8290\n","Epoch 33/100\n","12/12 [==============================] - 1s 107ms/step - loss: 0.4271 - masked_acc: 0.7549 - masked_auc: 0.8293 - val_loss: 0.4552 - val_masked_acc: 0.7553 - val_masked_auc: 0.8297\n","Epoch 34/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4236 - masked_acc: 0.7555 - masked_auc: 0.8300 - val_loss: 0.4560 - val_masked_acc: 0.7558 - val_masked_auc: 0.8303\n","Epoch 35/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4299 - masked_acc: 0.7560 - masked_auc: 0.8305 - val_loss: 0.4534 - val_masked_acc: 0.7563 - val_masked_auc: 0.8309\n","Epoch 36/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4245 - masked_acc: 0.7566 - masked_auc: 0.8312 - val_loss: 0.4516 - val_masked_acc: 0.7569 - val_masked_auc: 0.8316\n","Epoch 37/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4213 - masked_acc: 0.7572 - masked_auc: 0.8319 - val_loss: 0.4518 - val_masked_acc: 0.7575 - val_masked_auc: 0.8323\n","Epoch 38/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4188 - masked_acc: 0.7577 - masked_auc: 0.8325 - val_loss: 0.4513 - val_masked_acc: 0.7581 - val_masked_auc: 0.8330\n","Epoch 39/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4299 - masked_acc: 0.7583 - masked_auc: 0.8332 - val_loss: 0.4627 - val_masked_acc: 0.7586 - val_masked_auc: 0.8335\n","23/23 [==============================] - 1s 43ms/step - loss: 0.4208 - masked_acc: 0.7588 - masked_auc: 0.8338\n","3/3 [==============================] - 0s 38ms/step - loss: 0.5121 - masked_acc: 0.7591 - masked_auc: 0.8341\n","Test:  [0.5121400952339172, 0.75905442237854, 0.8340755105018616]\n","Epoch 1/100\n","12/12 [==============================] - 9s 248ms/step - loss: 0.6217 - masked_acc: 0.5277 - masked_auc: 0.5453 - val_loss: 0.5560 - val_masked_acc: 0.6003 - val_masked_auc: 0.6429\n","Epoch 2/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.5628 - masked_acc: 0.6181 - masked_auc: 0.6657 - val_loss: 0.4928 - val_masked_acc: 0.6473 - val_masked_auc: 0.7044\n","Epoch 3/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.5077 - masked_acc: 0.6582 - masked_auc: 0.7185 - val_loss: 0.4754 - val_masked_acc: 0.6746 - val_masked_auc: 0.7397\n","Epoch 4/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.5012 - masked_acc: 0.6801 - masked_auc: 0.7465 - val_loss: 0.4944 - val_masked_acc: 0.6887 - val_masked_auc: 0.7569\n","Epoch 5/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.5047 - masked_acc: 0.6922 - masked_auc: 0.7609 - val_loss: 0.4813 - val_masked_acc: 0.6979 - val_masked_auc: 0.7669\n","Epoch 6/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4918 - masked_acc: 0.7006 - masked_auc: 0.7700 - val_loss: 0.4679 - val_masked_acc: 0.7052 - val_masked_auc: 0.7750\n","Epoch 7/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4825 - masked_acc: 0.7070 - masked_auc: 0.7771 - val_loss: 0.4553 - val_masked_acc: 0.7109 - val_masked_auc: 0.7813\n","Epoch 8/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4698 - masked_acc: 0.7127 - masked_auc: 0.7833 - val_loss: 0.4498 - val_masked_acc: 0.7161 - val_masked_auc: 0.7873\n","Epoch 9/100\n","12/12 [==============================] - 1s 105ms/step - loss: 0.4663 - masked_acc: 0.7177 - masked_auc: 0.7890 - val_loss: 0.4552 - val_masked_acc: 0.7202 - val_masked_auc: 0.7921\n","Epoch 10/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4676 - masked_acc: 0.7215 - masked_auc: 0.7935 - val_loss: 0.4531 - val_masked_acc: 0.7235 - val_masked_auc: 0.7958\n","Epoch 11/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4818 - masked_acc: 0.7244 - masked_auc: 0.7966 - val_loss: 0.4514 - val_masked_acc: 0.7258 - val_masked_auc: 0.7982\n","Epoch 12/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4698 - masked_acc: 0.7267 - masked_auc: 0.7992 - val_loss: 0.4524 - val_masked_acc: 0.7283 - val_masked_auc: 0.8007\n","Epoch 13/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4637 - masked_acc: 0.7291 - masked_auc: 0.8015 - val_loss: 0.4463 - val_masked_acc: 0.7305 - val_masked_auc: 0.8032\n","Epoch 14/100\n","12/12 [==============================] - 1s 110ms/step - loss: 0.4600 - masked_acc: 0.7313 - masked_auc: 0.8041 - val_loss: 0.4401 - val_masked_acc: 0.7327 - val_masked_auc: 0.8057\n","Epoch 15/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4490 - masked_acc: 0.7334 - masked_auc: 0.8065 - val_loss: 0.4400 - val_masked_acc: 0.7347 - val_masked_auc: 0.8080\n","Epoch 16/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4535 - masked_acc: 0.7354 - masked_auc: 0.8088 - val_loss: 0.4432 - val_masked_acc: 0.7366 - val_masked_auc: 0.8102\n","Epoch 17/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4497 - masked_acc: 0.7372 - masked_auc: 0.8109 - val_loss: 0.4461 - val_masked_acc: 0.7383 - val_masked_auc: 0.8121\n","Epoch 18/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4575 - masked_acc: 0.7388 - masked_auc: 0.8126 - val_loss: 0.4544 - val_masked_acc: 0.7393 - val_masked_auc: 0.8132\n","Epoch 19/100\n","12/12 [==============================] - 1s 104ms/step - loss: 0.4652 - masked_acc: 0.7396 - masked_auc: 0.8135 - val_loss: 0.4530 - val_masked_acc: 0.7403 - val_masked_auc: 0.8142\n","Epoch 20/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4608 - masked_acc: 0.7406 - masked_auc: 0.8146 - val_loss: 0.4593 - val_masked_acc: 0.7412 - val_masked_auc: 0.8152\n","Epoch 21/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4558 - masked_acc: 0.7415 - masked_auc: 0.8155 - val_loss: 0.4482 - val_masked_acc: 0.7421 - val_masked_auc: 0.8162\n","Epoch 22/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4515 - masked_acc: 0.7425 - masked_auc: 0.8166 - val_loss: 0.4481 - val_masked_acc: 0.7431 - val_masked_auc: 0.8173\n","Epoch 23/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4452 - masked_acc: 0.7435 - masked_auc: 0.8178 - val_loss: 0.4475 - val_masked_acc: 0.7442 - val_masked_auc: 0.8186\n","Epoch 24/100\n","12/12 [==============================] - 1s 103ms/step - loss: 0.4396 - masked_acc: 0.7446 - masked_auc: 0.8190 - val_loss: 0.4488 - val_masked_acc: 0.7452 - val_masked_auc: 0.8197\n","Epoch 25/100\n","12/12 [==============================] - 1s 106ms/step - loss: 0.4412 - masked_acc: 0.7456 - masked_auc: 0.8201 - val_loss: 0.4488 - val_masked_acc: 0.7462 - val_masked_auc: 0.8209\n","23/23 [==============================] - 1s 41ms/step - loss: 0.4376 - masked_acc: 0.7467 - masked_auc: 0.8214\n","3/3 [==============================] - 0s 39ms/step - loss: 0.4940 - masked_acc: 0.7472 - masked_auc: 0.8218\n","Test:  [0.4940149188041687, 0.747169017791748, 0.8218403458595276]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QsVmumHMz3lx","executionInfo":{"status":"ok","timestamp":1616835108413,"user_tz":240,"elapsed":384232,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"3a7e99d2-a8c4-4b9b-c044-cf90e5fa7f10"},"source":["t_eval = np.array(test_eval)\n","print(\"test avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n","print(\"test avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n","print(\"test avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test avg loss:  0.4956098973751068 +/- 0.009004329765390178\n","test avg acc:  0.7524508953094482 +/- 0.004915822987043772\n","test avg auc:  0.8266466975212097 +/- 0.005394693000566721\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9MM_CXWz5K6","executionInfo":{"status":"ok","timestamp":1616835108414,"user_tz":240,"elapsed":384221,"user":{"displayName":"Yue Kuang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqLjoIOxCZhEa56jCT-3rAvsTfGU47wFz4FfIp=s64","userId":"16903014339608882219"}},"outputId":"8045b67a-bf10-45e4-d306-8ad867a99c6f"},"source":["t_eval = np.array(train_eval)\n","print(\"train avg loss: \", np.mean(t_eval[:, 0]), \"+/-\" ,np.std(t_eval[:, 0]))\n","print(\"train avg acc: \", np.mean(t_eval[:, 1]),  \"+/-\" ,np.std(t_eval[:, 1]))\n","print(\"train avg auc: \", np.mean(t_eval[:, 2]), \"+/-\" ,np.std(t_eval[:, 2]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train avg loss:  0.4279987752437592 +/- 0.011397843749356646\n","train avg acc:  0.7519938945770264 +/- 0.004975242841066693\n","train avg auc:  0.8261496067047119 +/- 0.005418478650433621\n"],"name":"stdout"}]}]}